\subsection{Optimization}

\subsubsection{Local Dead-End Elimination Algorithm}\ 

The dead-end elimination (DEE) algorithm is an efficient method to eliminate infeasible variable states. For a variable $x_v$, and two variable states $x_v^i$ and $x_v^j$ in $X_v$, if the following condition is satisfied, then state $x_v^i$ can be eliminated, which reduces the search space.
\begin{align}
& \theta_v(x_v^i)+\sum_{(u,v)\in E}\min_{x_u\in X_u}\theta_{uv}(x_u,x_v^i) \notag \\
>\ \ & \theta_v(x_v^j)+\sum_{(u,v)\in E}\max_{x_u\in X_u}\theta_{uv}(x_u,x_v^j)
\end{align}

The more powerful criterion that improved by \cite{goldstein1994efficient} is
\begin{align}
\theta_v(x_v^i)-\theta_v(x_v^j)+\sum_{(u,v)\in E}\min_{x_u\in X_u}[\theta_{uv}(x_u,x_v^i)-\theta_{uv}(x_u,x_v^j)] > 0
\end{align}

We apply the Goldstein DEE criterion in (2) to the function \textsc{Branch}. Let $D(X)$ be the set of variables that have been searched, and $U(X)=V\setminus D(X)$ be the set of variables which has not been determined yet. Consider two variable states $x_v^i$ and $x_v^j$ in an undetermined variable $x_v$, the Goldstein DEE criterion we use in the \textsc{Branch} functions is
\begin{align}
& \theta_v(x_v^i)-\theta_v(x_v^j)+\sum_{(u,v)\in E\wedge u\in D(X)}[\theta_{uv}(x_u,x_v^i)-\theta_{uv}(x_u,x_v^j)] \notag \\
& +\sum_{(u,v)\in E\wedge u\in U(X)}\min_{x_u\in X_u}[\theta_{uv}(x_u,x_v^i)-\theta_{uv}(x_u,x_v^j)] > 0
\end{align}

By applying the DEE criterion in Eq. (3), we can eliminate a large number of infeasible variable states, and thus significantly reduces the branch space.

Here, the DEE criterion is incorporated into each branch step. To distinguish it from most other DEE criteria that are applied before search algorithms (e.g. A*\cite[]{gainza2013osprey}), we call the criterion in Eq. (3) integrated into the branch step the \textit{local DEE criterion}.

\subsubsection{Lower Bound}\ 

\noindent\textbf{Naive Lower Bound.}
A naive lower bound of the energy function in protein design can be easily computed by considering the best possible rotamer assignment in each residue, which is
\begin{align}
\sum_{v\in V}\min_{x_v\in X_v}\left(\theta_v(x_v)+\sum_{u<v\wedge(u,v)\in E}\min_{x_u\in X_u}\theta_{uv}(x_u,x_v)\right)
\end{align}

That is, the naive lower bound of the current state space $X$ can be written as
\begin{align}
LB_1(X)=&g(X)+\sum_{v\in U(x)}\min_{x_v\in X_v}\left(\theta_v(x_v)+\sum_{u\in D(X)}\theta_{uv}(x_u,x_v)\notag\right. \\
&\left.+\sum_{u<v\wedge u\in U(X)}\min_{x_u\in X_u}\theta_{uv}(x_u,x_v)\right)
\end{align}
where we leave $(u,v)\in E$ out from the summation notation for simplifying the expression, and $g(X)$ is the energy of the determined variables (i.e. those residues in which the rotamers have been determined), that is
\[
g(X) = \sum_{v\in D(X)}\theta_v(x_v)+\sum_{u,v\in D(X)\wedge u<v}\theta_{uv}(x_u,x_v)
\]

\noindent\textbf{Efficient Lower Bound.}
By observing the formula of the naive lower bound, we see that every edge-energy function is only used for the vertex that has the greater index. If we split $\theta_{uv}$ into two functions $\beta_{uv}$ and $\beta_{vu}$ where $\beta_{uv}(x_u,x_v)+\beta_{vu}(x_v,x_u)=\theta_{uv}(x_u,x_v)$ for all $x_u,x_v$, then the formula of (4) becomes
\begin{align}
\max & \ \ \sum_{v\in V}\min_{x_v\in X_v}\left(\theta_v(x_v)+\sum_{(u,v)\in E}\min_{x_u\in X_u}\beta_{uv}(x_u,x_v)\right) \\
s.t. & \ \ \beta_{uv}(x_u,x_v)+\beta_{vu}(x_v,x_u)=\theta_{vu}(x_u,x_v) \notag \\
& \ \ \forall (u,v)\in E,x_u\in X_u,x_v\in X_v \notag
\end{align}

The above optimization problem is a convex dual of MAPLPR, which can be solved by Convergent Message Passing Algorithms \cite[]{globerson2008fixing}.

If we compute the best functions $\beta^*$, then the lower bound of the current state space $X$ becomes
\begin{align}
LB_2(X)=&g(X)+\sum_{v\in U(X)}\min_{x_v\in X_v}\left(\theta_v(x_v)+\sum_{u\in D(X)}\theta_{uv}(x_u,x_v)\right. \notag \\
&\left.+\sum_{u\in U(X)}\min_{x_u\in X_u}\beta_{uv}^*(x_u,x_v)\right)
\end{align}

Since $\beta^*$ may not be the best functions for any state space, it is necessary because we can not compute it for all the searched state space.

If we compute $LB_2$ directly, then the time complexity is $O(n^2m^2)$, where $n$ is the number of mutable residues, and $m$ is the number of rotamers per residue. If we firstly compute a table $p$ that $p_{uv}(x_v)=\min_{x_u\in X_u}\beta_{uv}^*(x_u,x_v)$ with time $O(n^2m^2)$ and space $O(n^2m)$, then the time of computing $LB_2$ decrease to $O(n^2m)$.

\noindent\textbf{Mini-Bucket.}
% (http://www.ics.uci.edu/~csp/r169.pdf)
The mini-bucket elimination (MBE) is a well-known approximation algorithm for graphical models, and it gives a bound when the induced width of the graph is too large. The idea of bucket elimination (BE) is to eliminate variables, and the pseudo-code is as follows.

\begin{algorithm}[!h]
\caption{Bucket Elimination}
\begin{algorithmic}[1]
\Function{BucketElimination}{$\mathcal{F},v$}
    \State $\mathcal{B} \gets \{f\in\mathcal{F}|v\in var(f)\}$
    \State $g \gets \mathcal{B}\Downarrow v$
    \State $\mathcal{F} \gets (\mathcal{F}\setminus \mathcal{B})\cup\{g\}$
    \State \textbf{return }$\mathcal{F}$
\EndFunction
\end{algorithmic}
\end{algorithm}

There the operation $\mathcal{B}\Downarrow v$ means combine the functions in $\mathcal{B}$ with eliminating the variable $v$. The time and space complexity of the algorithm is exponential in the largest scope of all the functions that computed.

Mini-bucket elimination has a parameter $z$ which restrict the size of the scopes of each functions, and also restrict the time and space complexity.
\begin{algorithm}
\caption{Mini-Bucket Elimination}
\begin{algorithmic}[1]
\Function{BucketElimination}{$\mathcal{F},v$}
    \State $\mathcal{B} \gets \{f\in\mathcal{F}|v\in var(f)\}$
    \State $(Q_1,Q_2,...,Q_m) \gets \textsc{Partition}(\mathcal{B},z)$
    \For {$i \gets 1$\textbf{ to }$m$}
        \State $g_i\gets Q_i\Downarrow v$
    \EndFor
    \State $\mathcal{F} \gets (\mathcal{F}\setminus \mathcal{B})\cup\{g_1,g_2,...,g_m\}$
    \State \textbf{return }$\mathcal{F}$
\EndFunction
\end{algorithmic}
\end{algorithm}

\textsc{Partition}$(\mathcal{B},z)$ means that divide $\mathcal{B}$ into parts $Q_1,Q_2,...,Q_m$ and $var(Q_i)\le z+1$ for $1\le i\le m$.

For the current state space $X$, we eliminate all the variables in $U(X)$, and then summarize all the functions on $D(X)$, then we get another lower bound of state space $X$.

\subsubsection{Upper Bound}\ 

Different with lower bound, we make the upper bound of state space $X$ be a better solution in $X$. There are many algorithm for finding a better solution of a problem, such as Simulated Annealing (SA), Genetic Algorithm.

We use Simulated Annealing as our upper bound algorithm. The initial state of SA is according to $LB_2$, which means
\begin{align*}
x_v^{0}\!=\!\arg\!\min_{x_v\in X_v}\left(\theta_v(x_v)\!+\!\sum_{u\in D(X)}\theta_{uv}(x_u,x_v)\!+\!\sum_{u\in U(X)}p_{uv}(x_v)\right)
\end{align*}

Let $\mathbf{x}^{S}$ be the best solution that find by Simulated Annealing Algorithm, then
\begin{align*}
  UB(X)=g(\mathbf{x}^{S})
\end{align*}

\subsection{Refinement on MapReduce}
    With some experiments we notice that each iteration can be done with a map-only job, in which we omit the reduce part. This significantly reduces running time since the shuffle between map and reduce will sort the data, which we do not need. However, this will cause many nodes not seeing the global minimum upper bound, which leads to fewer nodes discarded than in random grouping. To solve this, we use a \textit{parameter server}.

    We set up a web server which stores the global minimum upper bound and supports query and modify to the bound. In each map, we start another thread, which constantly check if the local minimum upper bound is updated, and if so, this thread will interact with the web server. This thread is independent from the map function and thus will bring very little overhead. But with the server, the output nodes of each iteration reduces abount $1/3$ to $1/2$.
